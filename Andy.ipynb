{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04e0500f-8246-4d00-b92d-b03fa96a3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd497656-d548-4e75-94af-91698d1538ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'aclImdb/train_X.txt' already exists. No new content was written.\n",
      "File 'aclImdb/train_y.txt' already exists. No new content was written.\n",
      "File 'aclImdb/test_X.txt' already exists. No new content was written.\n",
      "File 'aclImdb/test_y.txt' already exists. No new content was written.\n",
      "Training reviews: 25000\n",
      "Test reviews: 25000\n"
     ]
    }
   ],
   "source": [
    "def load_data_set(path):\n",
    "    imdb_X = []\n",
    "    imdb_y = []\n",
    "    \n",
    "    pos_folder = os.path.join(path, 'pos')\n",
    "    for filename in os.listdir(pos_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(pos_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                imdb_X.append(file.read())\n",
    "                imdb_y.append(1)\n",
    "                      \n",
    "    neg_folder = os.path.join(path, 'neg')\n",
    "    for filename in os.listdir(neg_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(neg_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                imdb_X.append(file.read())\n",
    "                imdb_y.append(0)\n",
    "\n",
    "    store_results(f'{path}_X.txt', imdb_X)\n",
    "    store_results(f'{path}_y.txt', imdb_y)\n",
    "    \n",
    "    return imdb_X, imdb_y\n",
    "\n",
    "def store_results(filename, data_list):\n",
    "    try:\n",
    "        with open(filename, 'x', encoding='utf-8') as f:\n",
    "            if (type(data_list[0]) == str):\n",
    "                for line in data_list:\n",
    "                    f.write(line + \"\\n\")\n",
    "            elif (type(data_list[0]) == int):\n",
    "                for line in data_list:\n",
    "                    f.write(str(line) + \"\\n\")\n",
    "        print(f\"File '{filename}' created and content written successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"File '{filename}' already exists. No new content was written.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "train_reviews, train_labels = load_data_set('aclImdb/train')\n",
    "test_reviews, test_labels = load_data_set('aclImdb/test')\n",
    "\n",
    "print(f\"Training reviews: {len(train_reviews)}\")\n",
    "print(f\"Test reviews: {len(test_reviews)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39aa3f83-a66b-412c-80c9-02c6254cb7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training reviews: 25000\n",
      "Test reviews: 25000\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "train_reviews = [preprocess(review) for review in train_reviews]\n",
    "test_reviews = [preprocess(review) for review in test_reviews]\n",
    "\n",
    "print(f\"Training reviews: {len(train_reviews)}\")\n",
    "print(f\"Test reviews: {len(test_reviews)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d87336b1-b699-49e5-bdef-d57fda801a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training reviews: (25000, 10000)\n",
      "Test reviews: (25000, 10000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000, \n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2)\n",
    ")\n",
    "X_tr = vectorizer.fit_transform(train_reviews)\n",
    "X_te = vectorizer.transform(test_reviews)\n",
    "\n",
    "print(f\"Training reviews: {X_tr.shape}\")\n",
    "print(f\"Test reviews: {X_te.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24f42f6b-a61b-40ca-8e2e-08f488a48dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Test Accuracy: 0.86588\n"
     ]
    }
   ],
   "source": [
    "learner = LinearSVC(C=1.0, class_weight='balanced', random_state=seed, max_iter=2000)\n",
    "learner.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = learner.predict(X_te)\n",
    "\n",
    "accuracy = accuracy_score(y_te, y_pred)\n",
    "print(f\"Linear SVM Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04647c1-de23-4c32-885c-af6abc9088a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
